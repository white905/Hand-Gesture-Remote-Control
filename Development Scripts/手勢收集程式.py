# -*- coding: utf-8 -*-
"""手勢收集程式.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aYYA_Nl2BS2ehwB0epyqgVo2nigOARvt

##**前置準備**
"""

pip install opencv-python

pip install mediapipe

pip install tensorflow

"""##**節點抓取**##"""

from pickletools import float8
import cv2
from cv2 import FONT_HERSHEY_SIMPLEX
import mediapipe as mp
import time
from math import sqrt
import numpy as np

rem = 0
ptime = 0
ctime = 0
word = 'a'
file_name = f'file_{word}'
gestrue_num = int(ord(word) - 97)

video = cv2.VideoCapture(0)
mpHands = mp.solutions.hands
hands = mpHands.Hands()
mpDraw = mp.solutions.drawing_utils
handLmsStyle = mpDraw.DrawingSpec(color = (0, 0, 255), thickness = 10)
handConStyle = mpDraw.DrawingSpec(color = (0, 255, 0), thickness = 5)

x_train = np.empty([100, 21, 2])

while True:
    ret, img = video.read()
    if ret:
        imgHeight = img.shape[0]
        imgWidth = img.shape[1]

        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        result = hands.process(imgRGB)
        if result.multi_hand_landmarks:
            for handLms in result.multi_hand_landmarks:
                mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS, handLmsStyle, handConStyle)

                x5 = int(handLms.landmark[5].x * imgWidth)
                y5 = int(handLms.landmark[5].y * imgHeight)

                for i, lm in enumerate(handLms.landmark):
                    xPos = int(lm.x * imgWidth)
                    yPos = int(lm.y * imgHeight)
                    cv2.putText(img, str(i), (xPos - 25, yPos + 5), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

                    # 紀錄節點0座標並以節點0座標為基準
                    if i == 0:
                        x0 = xPos
                        y0 = yPos
                    xPos = xPos - x0
                    yPos = y0 - yPos

                    # 翻正
                    x_turn = False
                    y_turn = False
                    if i == 1:
                        if xPos < 0:
                            x_turn = True
                        if yPos < 0:
                            y_turn = True
                    if x_turn == True:
                        xPos = -xPos
                    if y_turn == True:
                        yPos = -yPos

                    # 紀錄0 ~ 5的距離
                    if i == 0:
                        x5 = x5 - x0
                        y5 = y5 - y0
                        length_standard = sqrt(x5 * x5 + y5 * y5)
                    xPos_ch = (xPos / length_standard)
                    yPos_ch = (yPos / length_standard)

                    # x_train資料存取
                    x_train[rem, i, 0] = xPos_ch
                    x_train[rem, i, 1] = yPos_ch

                    print(i, xPos_ch, yPos_ch)

                rem += 1

        ctime = time.time()
        fps = 1 / (ctime - ptime)
        ptime = ctime
        # cv2.putText(img, f"FPS: {int(fps)}", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0))

        cv2.imshow('img', img)
    if cv2.waitKey(1) == ord('q'):
        break

    y_train = np.zeros((100, 26))
    for i in y_train:
        y_train[..., gestrue_num] = 1
    np.savez(file_name, x = x_train, y = y_train)

"""##**0926結合版本**##"""

from keras.models import load_model
import tensorflow as tf
from pickletools import float8
import cv2
from math import sqrt
from cv2 import FONT_HERSHEY_SIMPLEX
import mediapipe as mp
from math import sqrt
import numpy as np

# 下載model
model = load_model('0926_test_model.h5')

video = cv2.VideoCapture(0)
mpHands = mp.solutions.hands
hands = mpHands.Hands()
mpDraw = mp.solutions.drawing_utils
handLmsStyle = mpDraw.DrawingSpec(color = (0, 0, 255), thickness = 10)
handConStyle = mpDraw.DrawingSpec(color = (0, 255, 0), thickness = 5)

x_train = np.empty([21, 2])

while True:
    ret, img = video.read()
    if ret:
        imgHeight = img.shape[0]
        imgWidth = img.shape[1]

        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        result = hands.process(imgRGB)
        if result.multi_hand_landmarks:
            for handLms in result.multi_hand_landmarks:

                x5 = int(handLms.landmark[5].x * imgWidth)
                y5 = int(handLms.landmark[5].y * imgHeight)

                for i, lm in enumerate(handLms.landmark):
                    xPos = int(lm.x * imgWidth)
                    yPos = int(lm.y * imgHeight)

                    # 紀錄節點0座標並以節點0座標為基準
                    if i == 0:
                        x0 = xPos
                        y0 = yPos
                    xPos = xPos - x0
                    yPos = y0 - yPos

                    # 翻正
                    x_turn = False
                    y_turn = False
                    if i == 1:
                        if xPos < 0:
                            x_turn = True
                        if yPos < 0:
                            y_turn = True
                    if x_turn == True:
                        xPos = -xPos
                    if y_turn == True:
                        yPos = -yPos

                    # 紀錄0 ~ 5的距離
                    if i == 0:
                        x5 = x5 - x0
                        y5 = y5 - y0
                        length_standard = sqrt(x5 * x5 + y5 * y5)
                    xPos_ch = (xPos / length_standard)
                    yPos_ch = (yPos / length_standard)

                    x_train[i, 0] = xPos_ch
                    x_train[i, 1] = yPos_ch

                    # print(i, xPos_ch, yPos_ch)

                # 導入模型進行運算
                x_train = x_train.reshape((1, 42))
                predict = np.argmax(model.predict(x_train), axis = -1)
                print(chr(predict[0] + 97))

                x_train = np.zeros([21, 2])
                # rem += 1

        cv2.imshow('img', img)

    # 停止程式
    if cv2.waitKey(1) == ord('q'):
        break

"""##**1001等時距、相同不取**"""

import cv2
import time
import numpy as np
from math import sqrt
import mediapipe as mp
import tensorflow as tf
from pickletools import float8
from keras.models import load_model
from cv2 import FONT_HERSHEY_SIMPLEX

# 下載model
model = load_model('0926_test_model.h5')

ctime = 0
ptime = 0
pd_rem = 100
mpDraw = mp.solutions.drawing_utils
mpHands = mp.solutions.hands
video = cv2.VideoCapture(0)
hands = mpHands.Hands()

handLmsStyle = mpDraw.DrawingSpec(color = (0, 0, 255), thickness = 10)
handConStyle = mpDraw.DrawingSpec(color = (0, 255, 0), thickness = 5)

x_train = np.empty([21, 2])

while True:
    ret, img = video.read()
    ctime = time.time()

    # 每隔1秒判斷一次
    if (ctime - ptime >= 1):
        ptime = ctime

        if ret:
            imgHeight = img.shape[0]
            imgWidth = img.shape[1]

            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            result = hands.process(imgRGB)
            if result.multi_hand_landmarks:
                for handLms in result.multi_hand_landmarks:

                    x5 = int(handLms.landmark[5].x * imgWidth)
                    y5 = int(handLms.landmark[5].y * imgHeight)

                    for i, lm in enumerate(handLms.landmark):
                        xPos = int(lm.x * imgWidth)
                        yPos = int(lm.y * imgHeight)

                        # 紀錄節點0座標並以節點0座標為基準
                        if i == 0:
                            x0 = xPos
                            y0 = yPos
                        xPos = xPos - x0
                        yPos = y0 - yPos

                        # 翻正
                        x_turn = False
                        y_turn = False
                        if i == 1:
                            if xPos < 0:
                                x_turn = True
                            if yPos < 0:
                                y_turn = True
                        if x_turn == True:
                            xPos = -xPos
                        if y_turn == True:
                            yPos = -yPos

                        # 紀錄0 ~ 5的距離
                        if i == 0:
                            x5 = x5 - x0
                            y5 = y5 - y0
                            length_standard = sqrt(x5 * x5 + y5 * y5)
                        xPos_ch = (xPos / length_standard)
                        yPos_ch = (yPos / length_standard)

                        x_train[i, 0] = xPos_ch
                        x_train[i, 1] = yPos_ch

                    # 導入模型進行運算
                    x_train = x_train.reshape((1, 42))
                    predict = np.argmax(model.predict(x_train), axis = -1)

                    # 如果結果與之前相同則不運算
                    if (pd_rem != predict):
                        print(chr(predict[0] + 97))
                        pd_rem = predict

                    # 將陣列歸零
                    x_train = np.zeros([21, 2])

    # 投影畫面
    cv2.imshow('img', img)

    # 停止程式
    if cv2.waitKey(1) == ord('q'):
        break

"""##**1003去除雜訊**"""

import cv2
import time
import numpy as np
from math import sqrt
import mediapipe as mp
import tensorflow as tf
from pickletools import float8
from keras.models import load_model
from cv2 import FONT_HERSHEY_SIMPLEX

# 下載model
model = load_model('0926_test_model.h5')

ctime = 0
ptime = 0
pd_rem = 100
mpDraw = mp.solutions.drawing_utils
mpHands = mp.solutions.hands
video = cv2.VideoCapture(0)
hands = mpHands.Hands()

handLmsStyle = mpDraw.DrawingSpec(color = (0, 0, 255), thickness = 10)
handConStyle = mpDraw.DrawingSpec(color = (0, 255, 0), thickness = 5)

x_train = np.empty([21, 2])

while True:
    ret, img = video.read()
    ctime = time.time()

    # 每隔1秒判斷一次
    if (ctime - ptime >= 1):
        ptime = ctime

        if ret:
            imgHeight = img.shape[0]
            imgWidth = img.shape[1]

            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            result = hands.process(imgRGB)
            if result.multi_hand_landmarks:
                for handLms in result.multi_hand_landmarks:

                    x5 = int(handLms.landmark[5].x * imgWidth)
                    y5 = int(handLms.landmark[5].y * imgHeight)

                    for i, lm in enumerate(handLms.landmark):
                        xPos = int(lm.x * imgWidth)
                        yPos = int(lm.y * imgHeight)

                        # 紀錄節點0座標並以節點0座標為基準
                        if i == 0:
                            x0 = xPos
                            y0 = yPos
                        xPos = xPos - x0
                        yPos = y0 - yPos

                        # 翻正
                        x_turn = False
                        y_turn = False
                        if i == 1:
                            if xPos < 0:
                                x_turn = True
                            if yPos < 0:
                                y_turn = True
                        if x_turn == True:
                            xPos = -xPos
                        if y_turn == True:
                            yPos = -yPos

                        # 紀錄0 ~ 5的距離
                        if i == 0:
                            x5 = x5 - x0
                            y5 = y5 - y0
                            length_standard = sqrt(x5 * x5 + y5 * y5)
                        xPos_ch = (xPos / length_standard)
                        yPos_ch = (yPos / length_standard)

                        x_train[i, 0] = xPos_ch
                        x_train[i, 1] = yPos_ch

                    # 導入模型進行運算
                    x_train = x_train.reshape((1, 42))
                    predict = model.predict(x_train)
                    predict_max = np.argmax(predict, axis = -1)

                    # 準確率
                    # print(predict[0][predict_max[0]])

                    # 去除雜訊
                    if (predict[0][predict_max[0]] < 0.7):
                        predict_max = 100

                    # 如果結果與之前相同則不運算
                    if (pd_rem != predict_max):
                        if (predict_max == 100):
                            print("Recognition failed!")
                        else:
                            print(chr(predict_max[0] + 97))
                        pd_rem = predict_max

                    # 將陣列歸零
                    x_train = np.zeros([21, 2])

    # 投影畫面
    cv2.imshow('img', img)

    # 停止程式
    if cv2.waitKey(1) == ord('q'):
        break

"""##**測資確認及修改**"""

import numpy as np

gesture_num = 24
file_name = 'file_y.npz'

file_npz = np.load(file_name, encoding='bytes')
x_train = file_npz['x']
y = file_npz['y']
print(y[0])

# y_train = np.zeros((1000, 26))
# for i in y_train:
#     y_train[..., gesture_num] = 1

# np.savez(file_name, x = x_train, y = y_train)

"""##**1/2手部資料儲存最新版**"""

from pickletools import float8
import cv2
from cv2 import FONT_HERSHEY_SIMPLEX
import mediapipe as mp
import time
from math import sqrt
import numpy as np

# 參數調整區
data_num = 100
method = 1 # 1 = English, 2 = number
word = 'a'
wait_time = 3

# 各項參數
rem = 0
ctime = 0
ptime = 0
file_name = f'file_{word}'
video = cv2.VideoCapture(0)
mpHands = mp.solutions.hands
x_train = np.empty([data_num, 21, 2])
hands = mpHands.Hands()
mpDraw = mp.solutions.drawing_utils
handLmsStyle = mpDraw.DrawingSpec(color = (0, 0, 255), thickness = 10)
handConStyle = mpDraw.DrawingSpec(color = (0, 255, 0), thickness = 5)

# method轉換
if method == 1:
    gesture_num = int(ord(word) - 97)
elif method == 2:
    gesture_num = int(ord(word) - 48)

ctime = time.time()
ptime = ctime

while True:
    ret, img = video.read()
    if ret:
        imgHeight = img.shape[0]
        imgWidth = img.shape[1]

        # 等待時間
        if wait_time != 0:
            ctime = time.time()
            cv2.putText(img, str(wait_time), (int(imgHeight / 2), int(imgWidth / 2)), FONT_HERSHEY_SIMPLEX, 10, (0, 0, 0), 5)
            cv2.imshow('img', img)
            if ctime - ptime >= 1:
                ptime = ctime
                wait_time -= 1
                continue

        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        result = hands.process(imgRGB)
        if result.multi_hand_landmarks:
            for handLms in result.multi_hand_landmarks:
                mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS, handLmsStyle, handConStyle)

                x5 = int(handLms.landmark[5].x * imgWidth)
                y5 = int(handLms.landmark[5].y * imgHeight)

                for i, lm in enumerate(handLms.landmark):
                    xPos = int(lm.x * imgWidth)
                    yPos = int(lm.y * imgHeight)
                    cv2.putText(img, str(i), (xPos - 25, yPos + 5), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

                    # 紀錄節點0座標並以節點0座標為基準
                    if i == 0:
                        x0 = xPos
                        y0 = yPos
                    xPos = xPos - x0
                    yPos = y0 - yPos

                    # 翻正
                    x_turn = False
                    y_turn = False
                    if i == 1:
                        if xPos < 0:
                            x_turn = True
                        if yPos < 0:
                            y_turn = True
                    if x_turn == True:
                        xPos = -xPos
                    if y_turn == True:
                        yPos = -yPos

                    # 紀錄0 ~ 5的距離
                    if i == 0:
                        x5 = x5 - x0
                        y5 = y5 - y0
                        length_standard = sqrt(x5 * x5 + y5 * y5)
                    xPos_ch = (xPos / length_standard)
                    yPos_ch = (yPos / length_standard)

                    # x_train資料存取
                    x_train[rem, i, 0] = xPos_ch
                    x_train[rem, i, 1] = yPos_ch

                rem += 1

        cv2.imshow('img', img)
    if cv2.waitKey(1) == ord('q'):
        break
    if rem == data_num - 1:
        break
print(rem)
y_train = np.zeros((data_num, 26))
for i in y_train:
    y_train[..., gesture_num] = gesture_num
print("Whether save? (If yes, press the space bar)")
if cv2.waitKey() == ord(' '):
    np.savez(file_name, x = x_train, y = y_train)

"""##**0116加change版**"""

from pickletools import float8
import cv2
from cv2 import FONT_HERSHEY_SIMPLEX
import mediapipe as mp
import time
from math import sqrt
import numpy as np

# 參數調整區
data_num = 100
method = 1 # 1 = English, 2 = number
word = 'a' # change -> 切換mode
wait_time = 3

# change的設定
if word == 'change':
    gesture_num = 26

# 各項參數
rem = 0
ctime = 0
ptime = 0
hg_num = 0
file_name = f'file_{word}'
video = cv2.VideoCapture(0)
mpHands = mp.solutions.hands
x_train = np.empty([data_num, 21, 2])
hands = mpHands.Hands()
mpDraw = mp.solutions.drawing_utils
handLmsStyle = mpDraw.DrawingSpec(color = (0, 0, 255), thickness = 10)
handConStyle = mpDraw.DrawingSpec(color = (0, 255, 0), thickness = 5)

# method轉換
if method == 1 and word != 'change':
    gesture_num = int(ord(word) - 97)
    hg_num = 11

elif method == 2 and word != 'change':
    gesture_num = int(ord(word) - 48)
    hg_num = 27

ctime = time.time()
ptime = ctime

while True:
    ret, img = video.read()
    if ret:
        imgHeight = img.shape[0]
        imgWidth = img.shape[1]

        # 等待時間
        if wait_time != 0:
            ctime = time.time()
            cv2.putText(img, str(wait_time), (int(imgHeight / 2), int(imgWidth / 2)), FONT_HERSHEY_SIMPLEX, 10, (0, 0, 0), 5)
            cv2.imshow('img', img)
            if ctime - ptime >= 1:
                ptime = ctime
                wait_time -= 1
                continue

        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        result = hands.process(imgRGB)
        if result.multi_hand_landmarks:
            for handLms in result.multi_hand_landmarks:
                mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS, handLmsStyle, handConStyle)

                x5 = int(handLms.landmark[5].x * imgWidth)
                y5 = int(handLms.landmark[5].y * imgHeight)

                for i, lm in enumerate(handLms.landmark):
                    xPos = int(lm.x * imgWidth)
                    yPos = int(lm.y * imgHeight)
                    cv2.putText(img, str(i), (xPos - 25, yPos + 5), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

                    # 紀錄節點0座標並以節點0座標為基準
                    if i == 0:
                        x0 = xPos
                        y0 = yPos
                    xPos = xPos - x0
                    yPos = y0 - yPos

                    # 翻正
                    x_turn = False
                    y_turn = False
                    if i == 1:
                        if xPos < 0:
                            x_turn = True
                        if yPos < 0:
                            y_turn = True
                    if x_turn == True:
                        xPos = -xPos
                    if y_turn == True:
                        yPos = -yPos

                    # 紀錄0 ~ 5的距離
                    if i == 0:
                        x5 = x5 - x0
                        y5 = y5 - y0
                        length_standard = sqrt(x5 * x5 + y5 * y5)
                    xPos_ch = (xPos / length_standard)
                    yPos_ch = (yPos / length_standard)

                    # x_train資料存取
                    x_train[rem, i, 0] = xPos_ch
                    x_train[rem, i, 1] = yPos_ch

                rem += 1

        cv2.imshow('img', img)
    if cv2.waitKey(1) == ord('q'):
        break
    if rem == data_num - 1:
        break

y_train = np.zeros((data_num, hg_num))
for i in y_train:
    if word != 'change':
        y_train[..., gesture_num] = gesture_num
    else:
        y_train[..., hg_num - 1] = gesture_num

# 存檔確認
print("Whether save? (If yes, press the space bar)")
if cv2.waitKey() == ord(' '):
    np.savez(file_name, x = x_train, y = y_train)

"""##**可使用影片檔**"""

from pickletools import float8
import cv2
from cv2 import FONT_HERSHEY_SIMPLEX
import mediapipe as mp
import time
from math import sqrt
import numpy as np

# 參數調整區
data_num = 1000
method = 1 # 1 = English, 2 = number
word = 'change' # change -> 切換mode
wait_time = 3
video_method = 1 # 1 = camera, 2 = video(記得將檔名改成file_字母.mp4)

# 各項參數
rem = 0
ctime = 0
ptime = 0
hg_num = 0
file_name = f'file_{word}'
mpHands = mp.solutions.hands
x_train = np.empty([data_num, 21, 2])
hands = mpHands.Hands()
mpDraw = mp.solutions.drawing_utils
handLmsStyle = mpDraw.DrawingSpec(color = (0, 0, 255), thickness = 10)
handConStyle = mpDraw.DrawingSpec(color = (0, 255, 0), thickness = 5)

# video mode
if video_method == 1:
    video = cv2.VideoCapture(0)
else:
    video = cv2.VideoCapture(f'{file_name}.mp4')

# method轉換
if method == 1:
    if word != 'change':
        gesture_num = int(ord(word) - 97)
    hg_num = 27

elif method == 2:
    if word != 'change':
        gesture_num = int(ord(word) - 48)
    hg_num = 11

ctime = time.time()
ptime = ctime

while True:
    ret, img = video.read()
    if ret:
        imgHeight = img.shape[0]
        imgWidth = img.shape[1]

        # 等待時間
        if wait_time != 0:
            ctime = time.time()
            cv2.putText(img, str(wait_time), (int(imgHeight / 2), int(imgWidth / 2)), FONT_HERSHEY_SIMPLEX, 10, (0, 0, 0), 5)
            cv2.imshow('img', img)
            if ctime - ptime >= 1:
                ptime = ctime
                wait_time -= 1
                continue

        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        result = hands.process(imgRGB)
        if result.multi_hand_landmarks:
            for handLms in result.multi_hand_landmarks:
                mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS, handLmsStyle, handConStyle)

                x5 = int(handLms.landmark[5].x * imgWidth)
                y5 = int(handLms.landmark[5].y * imgHeight)

                for i, lm in enumerate(handLms.landmark):
                    xPos = int(lm.x * imgWidth)
                    yPos = int(lm.y * imgHeight)
                    cv2.putText(img, str(i), (xPos - 25, yPos + 5), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

                    # 紀錄節點0座標並以節點0座標為基準
                    if i == 0:
                        x0 = xPos
                        y0 = yPos
                    xPos = xPos - x0
                    yPos = y0 - yPos

                    # 翻正
                    x_turn = False
                    y_turn = False
                    if i == 1:
                        if xPos < 0:
                            x_turn = True
                        if yPos < 0:
                            y_turn = True
                    if x_turn == True:
                        xPos = -xPos
                    if y_turn == True:
                        yPos = -yPos

                    # 紀錄0 ~ 5的距離
                    if i == 0:
                        x5 = x5 - x0
                        y5 = y5 - y0
                        length_standard = sqrt(x5 * x5 + y5 * y5)
                    xPos_ch = (xPos / length_standard)
                    yPos_ch = (yPos / length_standard)

                    # x_train資料存取
                    x_train[rem, i, 0] = xPos_ch
                    x_train[rem, i, 1] = yPos_ch

                rem += 1

        cv2.imshow('img', img)
    if cv2.waitKey(1) == ord('q'):
        break
    if rem == data_num - 1:
        break

y_train = np.zeros((data_num, hg_num, 100))
for i in y_train:
    if word != 'change':
        y_train[..., gesture_num] = 1
    else:
        y_train[..., hg_num - 1] = 1

# 存檔確認
print("Whether save? (If yes, press the space bar)")
if cv2.waitKey() == ord(' '):
    np.savez(file_name, x = x_train, y = y_train)

"""##**擴增版本**"""

import cv2
import sys
import time
import numpy as np
from math import sqrt
import mediapipe as mp
from pickletools import float8
from cv2 import FONT_HERSHEY_SIMPLEX

# 參數調整區
data_num = 1000
method = 1 # 1 = English, 2 = number
word = 'change' # change -> 切換mode
wait_time = 3
video_method = 1 # 1 = camera, 2 = video(記得將檔名改成file_字母.mp4)

# 各項參數
rem = 0
ctime = 0
ptime = 0
hg_placed = 100
x_train = np.empty([data_num, 21, 2])
mpDraw = mp.solutions.drawing_utils
mpHands = mp.solutions.hands
file_name = f'file_{word}'
hands = mpHands.Hands()
handLmsStyle = mpDraw.DrawingSpec(color = (0, 140, 255), thickness = 6)
handConStyle = mpDraw.DrawingSpec(color = (255, 0, 0), thickness = 4)

# video mode
if video_method == 1:
    video = cv2.VideoCapture(0)
else:
    video = cv2.VideoCapture(f'{file_name}.mp4')

# method轉換
if method == 1 and word != 'change':
    gesture_num = int(ord(word) - 97)

elif method == 2 and word != 'change':
    gesture_num = int(ord(word) - 48)

ctime = time.time()
ptime = ctime

while True:
    ret, img = video.read()
    if ret:
        imgHeight = img.shape[0]
        imgWidth = img.shape[1]

        # 等待時間
        if wait_time != 0:
            ctime = time.time()
            cv2.putText(img, str(wait_time), (int(imgHeight / 2), int(imgWidth / 2)), FONT_HERSHEY_SIMPLEX, 10, (0, 0, 0), 5)
            if ctime - ptime >= 1:
                ptime = ctime
                wait_time -= 1
                continue

        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        result = hands.process(imgRGB)
        if result.multi_hand_landmarks:
            for handLms in result.multi_hand_landmarks:
                mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS, handLmsStyle, handConStyle)

                x5 = int(handLms.landmark[5].x * imgWidth)
                y5 = int(handLms.landmark[5].y * imgHeight)

                x_turn = False
                y_turn = False

                for i, lm in enumerate(handLms.landmark):
                    xPos = int(lm.x * imgWidth)
                    yPos = int(lm.y * imgHeight)
                    # cv2.putText(img, str(i), (xPos - 25, yPos + 5), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0)) # 節點數字

                    # 紀錄節點0座標並以節點0座標為基準
                    if i == 0:
                        x0 = xPos
                        y0 = yPos
                    xPos = xPos - x0
                    yPos = yPos - y0

                    # 將節點1定在第一象限
                    if i == 1:
                        if xPos < 0:
                            x_turn = True
                        if yPos < 0:
                            y_turn = True

                    # 翻正
                    if x_turn == True:
                        xPos = -xPos
                    if y_turn == True:
                        yPos = -yPos

                    # 紀錄0 ~ 5的距離
                    if i == 0:
                        x5 = x5 - x0
                        y5 = y5 - y0
                        length_standard = sqrt(x5 * x5 + y5 * y5)
                    xPos_ch = (xPos / length_standard)
                    yPos_ch = (yPos / length_standard)

                    # x_train資料存取
                    x_train[rem, i, 0] = xPos_ch
                    x_train[rem, i, 1] = yPos_ch

                rem += 1

        cv2.imshow('img', img)
    if cv2.waitKey(1) == ord('q'):
        sys.exit(0)
    if rem == data_num - 1:
        break

y_train = np.zeros((data_num, hg_placed))
for i in y_train:
    if word != 'change':
        y_train[..., gesture_num] = 1
    else:
        y_train[..., 26] = 1

# 存檔確認
print("Whether save? (If yes, press the space bar)")
if cv2.waitKey() == ord(' '):
    np.savez(file_name, x = x_train, y = y_train)
