# -*- coding: utf-8 -*-
"""模組.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pBxDLDigzNWMrn0dDgtI9UrcuU62lKFS

##**前置作業**
"""

pip install opencv-python

"""##**舊版**"""

import cv2
import time
from hg_model import *
import numpy as np
from math import sqrt
import mediapipe as mp
import tensorflow as tf
from pickletools import float8
from keras.models import load_model
from cv2 import FONT_HERSHEY_SIMPLEX
from ppadb.client import Client as AdbClient

# 下載model
model = load_model('1031_test_model_2+9+18_2_100_40.h5')

# 連接至裝置
client = AdbClient(host="127.0.0.1", port=5037) # Default is "127.0.0.1" and 5037
devices = client.devices()
device = devices[0]

# 變數區域
mode = 0
cmd = 1000
ctime = 0
ptime = 0
pd_rem = 100
predict_max = 100
implement = False
whether_output = True
mode_kind = ['tool mode', 'English mode', 'Number mode']
mpDraw = mp.solutions.drawing_utils
mpHands = mp.solutions.hands
video = cv2.VideoCapture(0)
hands = mpHands.Hands()

handLmsStyle = mpDraw.DrawingSpec(color = (0, 0, 255), thickness = 10)
handConStyle = mpDraw.DrawingSpec(color = (0, 255, 0), thickness = 5)

x_train = np.empty([21, 2])

while True:
    ret, img = video.read()
    ctime = time.time()
    cv2.putText(img, mode_kind[mode], (50, 50), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))
    cv2.putText(img, f'{chr(predict_max + 97)}', (50, 20), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

    # 每隔1秒判斷一次
    if (ctime - ptime >= 1):
        ptime = ctime

        if ret:
            imgHeight = img.shape[0]
            imgWidth = img.shape[1]

            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            result = hands.process(imgRGB)
            if result.multi_hand_landmarks:
                for handLms in result.multi_hand_landmarks:

                    x5 = int(handLms.landmark[5].x * imgWidth)
                    y5 = int(handLms.landmark[5].y * imgHeight)

                    for i, lm in enumerate(handLms.landmark):
                        xPos = int(lm.x * imgWidth)
                        yPos = int(lm.y * imgHeight)

                        # 紀錄節點0座標並以節點0座標為基準
                        if i == 0:
                            x0 = xPos
                            y0 = yPos
                        xPos = xPos - x0
                        yPos = y0 - yPos

                        # 翻正
                        x_turn = False
                        y_turn = False
                        if i == 1:
                            if xPos < 0:
                                x_turn = True
                            if yPos < 0:
                                y_turn = True
                        if x_turn == True:
                            xPos = -xPos
                        if y_turn == True:
                            yPos = -yPos

                        # 紀錄0 ~ 5的距離
                        if i == 0:
                            x5 = x5 - x0
                            y5 = y5 - y0
                            length_standard = sqrt(x5 * x5 + y5 * y5)
                        xPos_ch = (xPos / length_standard)
                        yPos_ch = (yPos / length_standard)

                        x_train[i, 0] = xPos_ch
                        x_train[i, 1] = yPos_ch

                    # 導入模型進行運算
                    x_train = x_train.reshape((1, 42))
                    predict = model.predict(x_train)
                    predict_max = np.argmax(predict, axis = -1)
                    predict_max = predict_max[0]

                    # 準確率
                    # print(predict[0][predict_max[0]])

                    # 去除雜訊
                    if (predict[0][predict_max] < 0.7):
                        predict_max = 100

                    # 如果結果與之前相同則不運算
                    if (pd_rem != predict_max):
                        if (predict_max == 100):
                            print("Recognition failed!")
                        else:
                            print(chr(predict_max + 97))
                            implement = True
                        pd_rem = predict_max

                    # mode切換
                    if (implement == True and predict_max == 24):
                        print('切換')
                        mode = (mode + 1) % len(mode_kind)

                    # 操作android系統
                    if (implement == True):

                        # 系統操作變換
                        if (mode == 0):
                            tool_cmd(predict_max)
                        elif (mode == 1):
                            english_cmd(predict_max)
                        elif (mode == 2):
                            number_cmd(predict_max)

                        # 輸出指令
                        if (whether_output == True):
                            print("work")
                            device.shell(f'input keyevent {cmd}')
                            implement = False

                    # 將陣列歸零
                    x_train = np.delete(x_train, slice(0, 42))
                    x_train = np.zeros([21, 2])

                    # 將output重新開啟
                    whether_output = True

    # 投影畫面
    cv2.imshow('img', img)

    # 停止程式
    if cv2.waitKey(1) == ord('q'):
        break

import time
from ppadb.client import Client as AdbClient

# 連線至裝置
def connect():
    client = AdbClient(host="127.0.0.1", port=5037) # Default is "127.0.0.1" and 5037

    devices = client.devices()

    if len(devices) == 0:
        print('No devices')
        quit()

    device = devices[0]

    print(f'Connected to {device}')

    return device, client

if __name__ == '__main__':
    device, client = connect()

# 滑動座標設定
upswipe = '500 300 500 600'
downswipe = '500 600 500 300'
leftswipe = '100 800 1000 800'
rightswipe = '1000 800 100 800'

def camera():
    device.shell(f'am start -n com.android.camera/.Camera')
    time.sleep(3)
    device.shell(f'input keyevent 24')
    print('拍照完成！')

def k_search():
    search_bar = '440 200'
    device.shell('input keyevent 64')
    query = input('你想搜尋(英文)：\n')
    search_query = f'{query}'
    device.shell(f'input tap {search_bar}')
    device.shell(f'input text "{search_query}"')

def l_screenshot():
    screenshot = device.screencap()
    with open('result.png', 'wb') as f:
        f.write(screenshot)
        print('截圖已存檔！')

def m_appOpen():
    command = {"youtube" : 'com.google.android.youtube/.HomeActivity',
           "line" : 'jp.naver.line.android/.activity.SplashActivity',
           "facebook" : 'com.facebook.katana/.LoginActivity',
           "google play" : 'com.android.vending/.AssetBrowserActivity',
           "google" : 'com.android.chrome/org.chromium.chrome.browser.ChromeTabbedActivity',
           "arknights" : 'tw.txwy.and.arknights/com.u8.sdk.U8UnityContext'}
    print(command.keys())
    Input = input('which app do you want to open?\n')
    device.shell(f'am start -n {command[Input]}')

def tool_cmd(predict_max):
    global cmd, whether_output
    if (predict_max == 0):
        cmd = '3'
    if (predict_max == 1):
        cmd = '26'
    if (predict_max == 2):
        cmd = '4'
    if (predict_max == 3):
        cmd = '24'
    if (predict_max == 5):
        cmd = '25'
    if (predict_max == 6):
        cmd = '66'
    if (predict_max == 7):
        cmd = '67'
    if (predict_max == 8):
        cmd = '278'
    if (predict_max == 10):
        cmd = '279'
    if (predict_max == 11):
        camera()
    if (predict_max == 14):
        k_search()
        time.sleep(3)
        whether_output = False
    if (predict_max == 15):
        l_screenshot()
        whether_output = False
    if (predict_max == 16):
        m_appOpen()
        whether_output = False
    if (predict_max == 17):
        device.shell(f'input swipe {upswipe}')
    if (predict_max == 18):
        device.shell(f'input swipe {downswipe}')
    if (predict_max == 19):
        device.shell(f'input swipe {leftswipe}')
    if (predict_max == 20):
        device.shell(f'input swipe {rightswipe}')
    if (predict_max == 21):
        cmd = '66'
        whether_output = False

def english_cmd(predict_max):
    global cmd
    cmd = f'{predict_max + 29}'

def number_cmd(predict_max):
    global cmd, whether_output
    if (predict_max < 10):
        cmd = f'{predict_max + 7}'
    else:
        print('temporarily unavailable')
        whether_output = False

def song():
    search_bar = '870 160'
    device.shell('am start -n com.google.android.youtube/.HomeActivity')
    device.shell(f'input tap {search_bar}')
    device.shell(f'input text "never gonna give you up"')
    time.sleep(1)
    device.shell('input keyevent 66')
    time.sleep(1)
    device.shell('input tap 620 1370')

"""##**12/10**"""

import cv2
import time
from hg_model import *
import numpy as np
from math import sqrt
import mediapipe as mp
import tensorflow as tf
from pickletools import float8
from keras.models import load_model
from cv2 import FONT_HERSHEY_SIMPLEX
from ppadb.client import Client as AdbClient

# 下載model
model = load_model('1031_test_model_2+9+18_2_100_40.h5')

# 連接至裝置
client = AdbClient(host="127.0.0.1", port=5037) # Default is "127.0.0.1" and 5037
devices = client.devices()
device = devices[0]

# 變數區域
mode = 0
ctime = 0
ptime = 0
pd_rem = 100
predict_max = 100
implement = False
whether_output = True
mode_kind = ['tool mode', 'English mode', 'Number mode']
mpHands = mp.solutions.hands
video = cv2.VideoCapture(0)
hands = mpHands.Hands()

x_train = np.empty([21, 2])

while True:
    ret, img = video.read()
    ctime = time.time()
    cv2.putText(img, mode_kind[mode], (50, 50), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))
    cv2.putText(img, f'{chr(predict_max + 97)}', (50, 20), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

    # 投影畫面
    cv2.imshow('img', img)

    # 每隔1秒判斷一次
    if (ctime - ptime >= 2):
        ptime = ctime

        if ret:
            imgHeight = img.shape[0]
            imgWidth = img.shape[1]

            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            result = hands.process(imgRGB)
            if result.multi_hand_landmarks:
                for handLms in result.multi_hand_landmarks:

                    x5 = int(handLms.landmark[5].x * imgWidth)
                    y5 = int(handLms.landmark[5].y * imgHeight)

                    for i, lm in enumerate(handLms.landmark):
                        xPos = int(lm.x * imgWidth)
                        yPos = int(lm.y * imgHeight)

                        # 紀錄節點0座標並以節點0座標為基準
                        if i == 0:
                            x0 = xPos
                            y0 = yPos
                        xPos = xPos - x0
                        yPos = y0 - yPos

                        # 翻正
                        x_turn = False
                        y_turn = False
                        if i == 1:
                            if xPos < 0:
                                x_turn = True
                            if yPos < 0:
                                y_turn = True
                        if x_turn == True:
                            xPos = -xPos
                        if y_turn == True:
                            yPos = -yPos

                        # 紀錄0 ~ 5的距離
                        if i == 0:
                            x5 = x5 - x0
                            y5 = y5 - y0
                            length_standard = sqrt(x5 * x5 + y5 * y5)
                        xPos_ch = (xPos / length_standard)
                        yPos_ch = (yPos / length_standard)

                        x_train[i, 0] = xPos_ch
                        x_train[i, 1] = yPos_ch

                    # 導入模型進行運算
                    x_train = x_train.reshape((1, 42))
                    predict = model.predict(x_train)
                    predict_max = np.argmax(predict, axis = -1)
                    predict_max = predict_max[0]

                    # 準確率
                    # print(predict[0][predict_max[0]])

                    # 去除雜訊
                    if (predict[0][predict_max] < 0.7):
                        predict_max = 100

                    # 如果結果與之前相同則不運算
                    if (pd_rem != predict_max):
                        if (predict_max == 100):
                            print("Recognition failed!")
                        else:
                            print(chr(predict_max + 97))
                            implement = True
                        pd_rem = predict_max

                    # mode切換
                    if (implement == True and predict_max == 24):
                        print('切換')
                        mode = (mode + 1) % len(mode_kind)

                    # 操作android系統
                    if (implement == True):

                        # 系統操作變換
                        if (mode == 0):
                            tool_cmd(predict_max)
                        elif (mode == 1):
                            english_cmd(predict_max)
                        elif (mode == 2):
                            number_cmd(predict_max)

                        # 輸出指令
                        if (whether_output == True):
                            print("work")
                            device.shell(f'input keyevent {cmd}')
                            implement = False

                    # 將陣列歸零
                    x_train = np.delete(x_train, slice(0, 42))
                    x_train = np.zeros([21, 2])

                    # 將output重新開啟
                    whether_output = True

    # 停止程式
    if cv2.waitKey(1) == ord('q'):
        break

"""##**12/12（recognize failed直接continue）**"""

import cv2
import time
from hg_model import *
import numpy as np
from math import sqrt
import mediapipe as mp
import tensorflow as tf
from pickletools import float8
from keras.models import load_model
from cv2 import FONT_HERSHEY_SIMPLEX
from ppadb.client import Client as AdbClient

# 下載model
model = load_model('1031_test_model_2+9+18_2_100_40.h5')

# 連接至裝置
client = AdbClient(host="127.0.0.1", port=5037) # Default is "127.0.0.1" and 5037
devices = client.devices()
device = devices[0]

# 變數區域
cmd = 0
mode = 0
ctime = 0
ptime = 0
pd_rem = 100
predict_max = 100
whether_output = True
mode_kind = ['tool mode', 'English mode', 'Number mode']
mpHands = mp.solutions.hands
video = cv2.VideoCapture(0)
hands = mpHands.Hands()

x_train = np.empty([21, 2])

def restore_initial_value():
    global x_train, whether_output, pd_rem, predict_max

    # 將陣列歸零
    x_train = np.delete(x_train, slice(0, 42))
    x_train = np.zeros([21, 2])

    # 將output重新開啟
    whether_output = True

    pd_rem = predict_max

while True:
    ret, img = video.read()
    ctime = time.time()
    cv2.putText(img, mode_kind[mode], (50, 50), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))
    cv2.putText(img, f'{chr(predict_max + 97)}', (50, 20), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

    # 投影畫面
    cv2.imshow('img', img)

    # 每隔1秒判斷一次
    if (ctime - ptime >= 2):
        ptime = ctime

        if ret:
            imgHeight = img.shape[0]
            imgWidth = img.shape[1]

            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            result = hands.process(imgRGB)
            if result.multi_hand_landmarks:
                for handLms in result.multi_hand_landmarks:

                    x5 = int(handLms.landmark[5].x * imgWidth)
                    y5 = int(handLms.landmark[5].y * imgHeight)

                    for i, lm in enumerate(handLms.landmark):
                        xPos = int(lm.x * imgWidth)
                        yPos = int(lm.y * imgHeight)

                        # 紀錄節點0座標並以節點0座標為基準
                        if i == 0:
                            x0 = xPos
                            y0 = yPos
                        xPos = xPos - x0
                        yPos = y0 - yPos

                        # 翻正
                        x_turn = False
                        y_turn = False
                        if i == 1:
                            if xPos < 0:
                                x_turn = True
                            if yPos < 0:
                                y_turn = True
                        if x_turn == True:
                            xPos = -xPos
                        if y_turn == True:
                            yPos = -yPos

                        # 紀錄0 ~ 5的距離
                        if i == 0:
                            x5 = x5 - x0
                            y5 = y5 - y0
                            length_standard = sqrt(x5 * x5 + y5 * y5)
                        xPos_ch = (xPos / length_standard)
                        yPos_ch = (yPos / length_standard)

                        x_train[i, 0] = xPos_ch
                        x_train[i, 1] = yPos_ch

                    # 導入模型進行運算
                    x_train = x_train.reshape((1, 42))
                    predict = model.predict(x_train)
                    predict_max = np.argmax(predict, axis = -1)
                    predict_max = predict_max[0]

                    # 準確率
                    # print(predict[0][predict_max[0]])

                    # 去除雜訊
                    if (predict[0][predict_max] < 0.7):
                        predict_max = 100

                    # 如果結果與之前相同則不運算
                    if (pd_rem != predict_max):
                        if (predict_max == 100):
                            print("Recognition failed!")
                            restore_initial_value()
                            continue
                        else:
                            print(chr(predict_max + 97))
                            implement = True


                    # mode切換
                    if (predict_max == 24):
                        print('切換')
                        mode = (mode + 1) % len(mode_kind)

                    # 操作android系統
                    if (implement == True):

                        # 系統操作變換
                        if (mode == 0):
                            tool_cmd(predict_max)
                        elif (mode == 1):
                            english_cmd(predict_max)
                        elif (mode == 2):
                            number_cmd(predict_max)

                        # 輸出指令
                        if (whether_output == True):
                            print("execute command!")
                            device.shell(f'input keyevent {cmd}')

                    restore_initial_value()

    # 停止程式
    if cv2.waitKey(1) == ord('q'):
        break

import time
from ppadb.client import Client as AdbClient

# 連線至裝置
def connect():
    client = AdbClient(host="127.0.0.1", port=5037) # Default is "127.0.0.1" and 5037

    devices = client.devices()

    if len(devices) == 0:
        print('No devices')
        quit()

    device = devices[0]

    print(f'Connected to {device}')

    return device, client

if __name__ == '__main__':
    device, client = connect()

# 滑動座標設定
upswipe = '500 300 500 600'
downswipe = '500 600 500 300'
leftswipe = '100 800 1000 800'
rightswipe = '1000 800 100 800'

# 搜尋座標設定
search_bar_num = 0
search_bar = ['440 200', '870 160']

def camera():
    global device
    device.shell(f'am start -n com.android.camera/.Camera')
    time.sleep(3)
    device.shell(f'input keyevent 24')
    print('拍照完成！')

def search():
    global device
    device.shell('input keyevent 64')
    query = input('你想搜尋(英文)：\n')
    search_query = f'{query}'
    device.shell(f'input tap {search_bar[search_bar_num]}')
    device.shell(f'input text "{search_query}"')
    time.sleep(1)
    device.shell('input keyevent 66')
    time.sleep(1)

def screenshot():
    global device
    screenshot = device.screencap()
    with open('result.png', 'wb') as f:
        f.write(screenshot)
        print('截圖已存檔！')

def appOpen():
    global search_bar_num, device
    command = {"youtube" : 'com.google.android.youtube/.HomeActivity',
           "line" : 'jp.naver.line.android/.activity.SplashActivity',
           "facebook" : 'com.facebook.katana/.LoginActivity',
           "google play" : 'com.android.vending/.AssetBrowserActivity',
           "google" : 'com.android.chrome/org.chromium.chrome.browser.ChromeTabbedActivity',
           "arknights" : 'tw.txwy.and.arknights/com.u8.sdk.U8UnityContext'}
    print(command.keys())
    Input = input('which app do you want to open?\n')
    if Input == 'youtube':
        search_bar_num = 0
    elif Input == 'google':
        search_bar_num = 1
    device.shell(f'am start -n {command[Input]}')

def tool_cmd(predict_max):
    global cmd, whether_output, device
    if (predict_max == 0):
        cmd = '3'
    if (predict_max == 1):
        cmd = '26'
    if (predict_max == 2):
        cmd = '4'
    if (predict_max == 3):
        cmd = '24'
    if (predict_max == 5):
        cmd = '25'
    if (predict_max == 6):
        cmd = '66'
    if (predict_max == 7):
        cmd = '67'
    if (predict_max == 8):
        cmd = '278'
    if (predict_max == 10):
        cmd = '279'
    if (predict_max == 11):
        camera()
    if (predict_max == 14):
        search()
        whether_output = False
    if (predict_max == 15):
        screenshot()
        whether_output = False
    if (predict_max == 16):
        appOpen()
        whether_output = False
    if (predict_max == 17):
        device.shell(f'input swipe {upswipe}')
        whether_output = False
    if (predict_max == 18):
        device.shell(f'input swipe {downswipe}')
        whether_output = False
    if (predict_max == 19):
        device.shell(f'input swipe {leftswipe}')
        whether_output = False
    if (predict_max == 20):
        device.shell(f'input swipe {rightswipe}')
        whether_output = False
    if (predict_max == 21):
        cmd = '66'

def english_cmd(predict_max):
    global cmd, device
    cmd = f'{predict_max + 29}'

def number_cmd(predict_max):
    global cmd, whether_output, device
    if (predict_max < 10):
        cmd = f'{predict_max + 7}'
    else:
        print('temporarily unavailable')
        whether_output = False

"""##**統合版**"""

import cv2
import time
import numpy as np
from math import sqrt
import mediapipe as mp
import tensorflow as tf
from pickletools import float8
from keras.models import load_model
from cv2 import FONT_HERSHEY_SIMPLEX
from ppadb.client import Client as AdbClient

# 下載model
model = load_model('1031_test_model_2+9+18_2_100_40.h5')

# 變數區域
cmd = 0
mode = 0
ctime = 0
ptime = 0
pd_rem = 100
predict_max = 100
whether_output = True
mode_kind = ['tool mode', 'English mode', 'Number mode']
mpHands = mp.solutions.hands
video = cv2.VideoCapture(0)
hands = mpHands.Hands()

x_train = np.empty([21, 2])

# 連線至裝置
def connect():
    client = AdbClient(host="127.0.0.1", port=5037) # Default is "127.0.0.1" and 5037

    devices = client.devices()

    if len(devices) == 0:
        print('No devices')
        quit()

    device = devices[0]

    print(f'Connected to {device}')

    return device, client

if __name__ == '__main__':
    device, client = connect()

def restore_initial_value():
    global x_train, whether_output, pd_rem, predict_max

    # 將陣列歸零
    x_train = np.delete(x_train, slice(0, 42))
    x_train = np.zeros([21, 2])

    # 將output重新開啟
    whether_output = True

    pd_rem = predict_max

# 滑動座標設定
upswipe = '500 300 500 600'
downswipe = '500 600 500 300'
leftswipe = '100 800 1000 800'
rightswipe = '1000 800 100 800'

# 搜尋座標設定
search_bar_num = 0
search_bar = ['870 160', '440 200']
youtube_coordinate = ['500 650', '500 1700']
phone_coordinate = ['790 2050 790 1000', '550 2050', '300 2050 300 1000']

def camera():
    global device
    device.shell(f'am start -n com.android.camera/.Camera')
    time.sleep(3)
    device.shell(f'input keyevent 24')
    print('拍照完成！')

def search():
    global device
    query = input('你想搜尋(英文)：\n')
    search_query = f'{query}'
    device.shell(f'input tap {search_bar[search_bar_num]}')
    device.shell(f'input text "{search_query}"')
    time.sleep(1)
    device.shell('input keyevent 66')
    time.sleep(1)

def screenshot():
    global device
    screenshot = device.screencap()
    with open('result.png', 'wb') as f:
        f.write(screenshot)
        print('截圖已存檔！')

def appOpen():
    global search_bar_num, device
    command = {"youtube" : 'com.google.android.youtube/.HomeActivity',
           "line" : 'jp.naver.line.android/.activity.SplashActivity',
           "facebook" : 'com.facebook.katana/.LoginActivity',
           "google play" : 'com.android.vending/.AssetBrowserActivity',
           "google" : 'com.android.chrome/org.chromium.chrome.browser.ChromeTabbedActivity',
           "arknights" : 'tw.txwy.and.arknights/com.u8.sdk.U8UnityContext'}
    print(command.keys())
    Input = input('which app do you want to open?\n')
    if Input == 'youtube':
        search_bar_num = 0
    elif Input == 'google':
        search_bar_num = 1
    device.shell(f'am start -n {command[Input]}')

def choose():
    choose = input('Which one?')
    device.shell(f'input tap {youtube_coordinate[int(choose) - 1]}')

def tool_cmd(predict_max):
    global cmd, whether_output, device
    # a
    if (predict_max == 0):
        cmd = '3'
    # b
    if (predict_max == 1):
        cmd = '26'
    # c
    if (predict_max == 2):
        cmd = '4'
    # d
    if (predict_max == 3):
        cmd = '24'
    # f
    if (predict_max == 5):
        cmd = '25'
    # g
    if (predict_max == 6):
        cmd = '66'
    # h
    if (predict_max == 7):
        cmd = '67'
    # i
    if (predict_max == 8):
        device.shell(f'input swipe {phone_coordinate[0]}')
        whether_output = False
    # k
    if (predict_max == 10):
        device.shell(f'input tap {phone_coordinate[1]}')
        whether_output = False
    # l
    if (predict_max == 11):
        camera()
    # o
    if (predict_max == 14):
        search()
        whether_output = False
    # p
    if (predict_max == 15):
        screenshot()
        whether_output = False
    # q
    if (predict_max == 16):
        appOpen()
        whether_output = False
    # r
    if (predict_max == 17):
        device.shell(f'input swipe {upswipe}')
        whether_output = False
    # s
    if (predict_max == 18):
        device.shell(f'input swipe {downswipe}')
        whether_output = False
    # t
    if (predict_max == 19):
        device.shell(f'input swipe {leftswipe}')
        whether_output = False
    # u
    if (predict_max == 20):
        device.shell(f'input swipe {rightswipe}')
        whether_output = False
    # v
    if (predict_max == 21):
        choose()
        whether_output = False
    # w
    if (predict_max == 22):
        device.shell(f'input swipe {phone_coordinate[2]}')
        whether_output = False


def english_cmd(predict_max):
    global cmd, device
    cmd = f'{predict_max + 29}'

def number_cmd(predict_max):
    global cmd, whether_output, device
    if (predict_max < 10):
        cmd = f'{predict_max + 7}'
    else:
        print('temporarily unavailable')
        whether_output = False

while True:
    ret, img = video.read()
    ctime = time.time()
    cv2.putText(img, mode_kind[mode], (50, 50), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))
    cv2.putText(img, f'{chr(predict_max + 97)}', (50, 20), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

    # 投影畫面
    cv2.imshow('img', img)

    # 每隔1秒判斷一次
    if (ctime - ptime >= 2):
        ptime = ctime

        if ret:
            imgHeight = img.shape[0]
            imgWidth = img.shape[1]

            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            result = hands.process(imgRGB)
            if result.multi_hand_landmarks:
                for handLms in result.multi_hand_landmarks:

                    x5 = int(handLms.landmark[5].x * imgWidth)
                    y5 = int(handLms.landmark[5].y * imgHeight)

                    for i, lm in enumerate(handLms.landmark):
                        xPos = int(lm.x * imgWidth)
                        yPos = int(lm.y * imgHeight)

                        # 紀錄節點0座標並以節點0座標為基準
                        if i == 0:
                            x0 = xPos
                            y0 = yPos
                        xPos = xPos - x0
                        yPos = y0 - yPos

                        # 翻正
                        x_turn = False
                        y_turn = False
                        if i == 1:
                            if xPos < 0:
                                x_turn = True
                            if yPos < 0:
                                y_turn = True
                        if x_turn == True:
                            xPos = -xPos
                        if y_turn == True:
                            yPos = -yPos

                        # 紀錄0 ~ 5的距離
                        if i == 0:
                            x5 = x5 - x0
                            y5 = y5 - y0
                            length_standard = sqrt(x5 * x5 + y5 * y5)
                        xPos_ch = (xPos / length_standard)
                        yPos_ch = (yPos / length_standard)

                        x_train[i, 0] = xPos_ch
                        x_train[i, 1] = yPos_ch

                    # 導入模型進行運算
                    x_train = x_train.reshape((1, 42))
                    predict = model.predict(x_train)
                    predict_max = np.argmax(predict, axis = -1)
                    predict_max = predict_max[0]

                    # 準確率
                    # print(predict[0][predict_max[0]])

                    # 去除雜訊
                    if (predict[0][predict_max] < 0.7):
                        predict_max = 100

                    # 如果結果與之前相同則不運算
                    if (pd_rem != predict_max):
                        if (predict_max == 100):
                            print("Recognition failed!")
                            restore_initial_value()
                            continue
                        else:
                            print(chr(predict_max + 97))
                            implement = True


                    # mode切換
                    if (predict_max == 24):
                        print('切換')
                        mode = (mode + 1) % len(mode_kind)


                    # 系統操作變換
                    if (mode == 0):
                        tool_cmd(predict_max)
                    elif (mode == 1):
                        english_cmd(predict_max)
                    elif (mode == 2):
                        number_cmd(predict_max)

                    # 輸出指令
                    if (whether_output == True):
                        print("execute command!")
                        device.shell(f'input keyevent {cmd}')

                    restore_initial_value()

    # 停止程式
    if cv2.waitKey(1) == ord('q'):
        break

"""##**0109**"""

import cv2
import time
import numpy as np
from math import sqrt
import mediapipe as mp
from keras.models import load_model
from cv2 import FONT_HERSHEY_SIMPLEX
from ppadb.client import Client as AdbClient

# 下載model
model = load_model('1031_test_model_2+9+18_2_100_40.h5')

# 變數區域
cmd = 0
mode = 0
ctime = 0
ptime = 0
pd_rem = 100
predict_max = 100
whether_output = True
mode_kind = ['tool mode', 'English mode', 'Number mode']
mpHands = mp.solutions.hands
video = cv2.VideoCapture(0)
hands = mpHands.Hands()

x_train = np.empty([21, 2])

# 連線至裝置
def connect():
    client = AdbClient(host="127.0.0.1", port=5037) # Default is "127.0.0.1" and 5037

    devices = client.devices()

    if len(devices) == 0:
        print('No devices')
        quit()

    device = devices[0]

    print(f'Connected to {device}')

    return device, client

if __name__ == '__main__':
    device, client = connect()

def restore_initial_value():
    global x_train, pd_rem, predict_max

    # 將陣列歸零
    x_train = np.delete(x_train, slice(0, 42))
    x_train = np.zeros([21, 2])

    # 記錄前一個手勢
    pd_rem = predict_max

# 拍攝照片
shot = '550 2035'

# 中心點
center = '550 1200'

# 滑動座標設定
upswipe = '500 300 500 600'
downswipe = '500 600 500 300'
leftswipe = '100 800 1000 800'
rightswipe = '1000 800 100 800'

# 搜尋座標設定
search_bar_num = 0
search_bar = ['870 160', '440 200']
youtube_coordinate = ['500 650', '500 1700']
phone_coordinate = ['790 2050 790 1000', '550 2050', '300 2050 300 1000']

def search():
    global device
    query = input('你想搜尋(英文)：\n')
    search_query = f'{query}'
    device.shell(f'input tap {search_bar[search_bar_num]}')
    device.shell(f'input text "{search_query}"')
    time.sleep(1)
    device.shell('input keyevent 66')
    time.sleep(1)

def screenshot():
    global device
    screenshot = device.screencap()
    with open('result.png', 'wb') as f:
        f.write(screenshot)
        print('截圖已存檔！')

def appOpen():
    global search_bar_num, device
    command = {"youtube" : 'com.google.android.youtube/.HomeActivity',
           "line" : 'jp.naver.line.android/.activity.SplashActivity',
           "facebook" : 'com.facebook.katana/.LoginActivity',
           "google play" : 'com.android.vending/.AssetBrowserActivity',
           "google" : 'com.android.chrome/org.chromium.chrome.browser.ChromeTabbedActivity',
           "arknights" : 'tw.txwy.and.arknights/com.u8.sdk.U8UnityContext',
           "camera" : 'com.android.camera/.Camera'}
    print(command.keys())
    Input = input('which app do you want to open?\n')
    if Input == 'youtube':
        search_bar_num = 0
    elif Input == 'google':
        search_bar_num = 1
    device.shell(f'am start -n {command[Input]}')

def choose():
    choose = input('Which one?')
    device.shell(f'input tap {youtube_coordinate[int(choose) - 1]}')

def tool_cmd(predict_max):
    global cmd, device
    # a
    if (predict_max == 0):
        cmd = '26'
    # b
    elif (predict_max == 1):
        cmd = '3'
    # c
    elif (predict_max == 2):
        cmd = '4'
    # d
    elif (predict_max == 3):
        cmd = '221'
    # e
    elif (predict_max == 4):
        cmd = '220'
    # f
    elif (predict_max == 5):
        cmd = '24'
    # g
    elif (predict_max == 6):
        cmd = '25'
    # h
    elif (predict_max == 7):
        device.shell(f'input swipe {upswipe}')
    # i
    elif (predict_max == 8):
        device.shell(f'input swipe {downswipe}')
    # j
    elif (predict_max == 9):
        device.shell(f'input swipe {leftswipe}')
    # k
    elif (predict_max == 10):
        device.shell(f'input swipe {rightswipe}')
    # l
    elif (predict_max == 11):
        cmd = '66'
    # m
    elif (predict_max == 12):
        cmd = '67'
    # n
    elif (predict_max == 13):
        device.shell(f'input swipe {phone_coordinate[0]}')
    # o
    elif (predict_max == 14):
        device.shell(f'input tap {phone_coordinate[1]}')
    # p
    elif (predict_max == 15):
        device.shell(f'input swipe {phone_coordinate[2]}')
    # q
    elif (predict_max == 16):
        device.shell(f'input tap {shot}')
    # r
    elif (predict_max == 17):
        screenshot()
    # s
    elif (predict_max == 18):
        appOpen()
    # t
    elif (predict_max == 19):
        search()
    # u
    elif (predict_max == 20):
        choose()
    # v
    elif (predict_max == 21):
        device.shell('input keyevent --longpress KEYCODE_POWER')
    # w
    elif (predict_max == 22):
        device.shell(f'input tap {center}')
        device.shell(f'input tap {center}')
    # x
    elif (predict_max == 23):
        device.shell('input wm density 480')
    # y
    elif (predict_max == 24):
        device.shell('input wm density 360')
    # z
    elif (predict_max == 25):
        device.shell('input wm density reset')



def english_cmd(predict_max):
    global cmd, device
    cmd = f'{predict_max + 29}'

def number_cmd(predict_max):
    global cmd, device
    if (predict_max < 10):
        cmd = f'{predict_max + 7}'
    else:
        print('temporarily unavailable')
        cmd = '-1'

while True:
    ret, img = video.read()
    ctime = time.time()
    cv2.putText(img, mode_kind[mode], (50, 50), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))
    cv2.putText(img, f'{chr(predict_max + 97)}', (50, 20), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

    # 投影畫面
    cv2.imshow('img', img)

    # 每隔1秒判斷一次
    if (ctime - ptime >= 2):
        ptime = ctime

        if ret:
            imgHeight = img.shape[0]
            imgWidth = img.shape[1]

            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            result = hands.process(imgRGB)
            if result.multi_hand_landmarks:
                for handLms in result.multi_hand_landmarks:

                    x5 = int(handLms.landmark[5].x * imgWidth)
                    y5 = int(handLms.landmark[5].y * imgHeight)

                    for i, lm in enumerate(handLms.landmark):
                        xPos = int(lm.x * imgWidth)
                        yPos = int(lm.y * imgHeight)

                        # 紀錄節點0座標並以節點0座標為基準
                        if i == 0:
                            x0 = xPos
                            y0 = yPos
                        xPos = xPos - x0
                        yPos = y0 - yPos

                        # 翻正
                        x_turn = False
                        y_turn = False
                        if i == 1:
                            if xPos < 0:
                                x_turn = True
                            if yPos < 0:
                                y_turn = True
                        if x_turn == True:
                            xPos = -xPos
                        if y_turn == True:
                            yPos = -yPos

                        # 紀錄0 ~ 5的距離
                        if i == 0:
                            x5 = x5 - x0
                            y5 = y5 - y0
                            length_standard = sqrt(x5 * x5 + y5 * y5)
                        xPos_ch = (xPos / length_standard)
                        yPos_ch = (yPos / length_standard)

                        x_train[i, 0] = xPos_ch
                        x_train[i, 1] = yPos_ch

                    # 導入模型進行運算
                    x_train = x_train.reshape((1, 42))
                    predict = model.predict(x_train)
                    predict_max = np.argmax(predict, axis = -1)
                    predict_max = predict_max[0]

                    # 準確率
                    # print(predict[0][predict_max[0]])

                    # 去除雜訊
                    if (predict[0][predict_max] < 0.7):
                        predict_max = 100

                    # 如果結果與之前相同則不運算
                    if (pd_rem != predict_max):
                        if (predict_max == 100):
                            print("Recognition failed!")
                            restore_initial_value()
                            continue

                    # 印出辨識結果
                    print(chr(predict_max + 97))

                    # mode切換
                    if (predict_max == 26):
                        print('切換')
                        mode = (mode + 1) % len(mode_kind)

                    # 系統操作變換
                    if (mode == 0):
                        tool_cmd(predict_max)
                    elif (mode == 1):
                        english_cmd(predict_max)
                    elif (mode == 2):
                        number_cmd(predict_max)

                    # 輸出指令
                    if (cmd != '-1'):
                        print("execute command!")
                        device.shell(f'input keyevent {cmd}')
                        cmd = '-1'

                    restore_initial_value()

    # 停止程式
    if cv2.waitKey(1) == ord('q'):
        break

"""##**0116**"""

import cv2
import time
import numpy as np
from math import sqrt
import mediapipe as mp
from keras.models import load_model
from cv2 import FONT_HERSHEY_SIMPLEX
from ppadb.client import Client as AdbClient

# 下載model
model_english = load_model('model_english.h5')
model_number = load_model('model_number.h5')

# 變數區域
cmd = 0
mode = 0
ctime = 0
ptime = 0
pd_rem = 100
predict_max = 100
whether_output = True
mode_kind = ['tool mode', 'English mode', 'Number mode']
mpHands = mp.solutions.hands
video = cv2.VideoCapture(0)
hands = mpHands.Hands()

x_train = np.empty([21, 2])

# 連線至裝置
def connect():
    client = AdbClient(host="127.0.0.1", port=5037) # Default is "127.0.0.1" and 5037

    devices = client.devices()

    if len(devices) == 0:
        print('No devices')
        quit()

    device = devices[0]

    print(f'Connected to {device}')

    return device, client

if __name__ == '__main__':
    device, client = connect()

def restore_initial_value():
    global x_train, pd_rem, predict_max

    # 將陣列歸零
    x_train = np.delete(x_train, slice(0, 42))
    x_train = np.zeros([21, 2])

    # 記錄前一個手勢
    pd_rem = predict_max

# 拍攝照片
shot = '550 2035'

# 中心點
center = '550 1200'

# 滑動座標設定
upswipe = '500 300 500 600'
downswipe = '500 600 500 300'
leftswipe = '100 800 1000 800'
rightswipe = '1000 800 100 800'

# 搜尋座標設定
search_bar_num = 0
search_bar = ['870 160', '440 200']
youtube_coordinate = ['500 650', '500 1700']
phone_coordinate = ['790 2050 790 1000', '550 2050', '300 2050 300 1000']

def search():
    global device
    query = input('你想搜尋(英文)：\n')
    search_query = f'{query}'
    device.shell(f'input tap {search_bar[search_bar_num]}')
    device.shell(f'input text "{search_query}"')
    time.sleep(1)
    device.shell('input keyevent 66')
    time.sleep(1)

def screenshot():
    global device
    screenshot = device.screencap()
    with open('result.png', 'wb') as f:
        f.write(screenshot)
        print('截圖已存檔！')

def appOpen():
    global search_bar_num, device
    command = {"youtube" : 'com.google.android.youtube/.HomeActivity',
           "line" : 'jp.naver.line.android/.activity.SplashActivity',
           "facebook" : 'com.facebook.katana/.LoginActivity',
           "google play" : 'com.android.vending/.AssetBrowserActivity',
           "google" : 'com.android.chrome/org.chromium.chrome.browser.ChromeTabbedActivity',
           "arknights" : 'tw.txwy.and.arknights/com.u8.sdk.U8UnityContext',
           "camera" : 'com.android.camera/.Camera'}
    print(command.keys())
    Input = input('which app do you want to open?\n')
    if Input == 'youtube':
        search_bar_num = 0
    elif Input == 'google':
        search_bar_num = 1
    device.shell(f'am start -n {command[Input]}')

def choose():
    choose = input('Which one?')
    device.shell(f'input tap {youtube_coordinate[int(choose) - 1]}')

def tool_cmd(predict_max):
    global cmd, device
    # a
    if predict_max == 0:
        cmd = '26'
    # b
    elif predict_max == 1:
        cmd = '3'
    # c
    elif predict_max == 2:
        cmd = '4'
    # d
    elif predict_max == 3:
        cmd = '221'
    # e
    elif predict_max == 4:
        cmd = '220'
    # f
    elif predict_max == 5:
        cmd = '24'
    # g
    elif predict_max == 6:
        cmd = '25'
    # h
    elif predict_max == 7:
        device.shell(f'input swipe {upswipe}')
    # i
    elif predict_max == 8:
        device.shell(f'input swipe {downswipe}')
    # j
    elif predict_max == 9:
        device.shell(f'input swipe {leftswipe}')
    # k
    elif predict_max == 10:
        device.shell(f'input swipe {rightswipe}')
    # l
    elif predict_max == 11:
        cmd = '66'
    # m
    elif predict_max == 12:
        cmd = '67'
    # n
    elif predict_max == 13:
        device.shell(f'input swipe {phone_coordinate[0]}')
    # o
    elif predict_max == 14:
        device.shell(f'input tap {phone_coordinate[1]}')
    # p
    elif predict_max == 15:
        device.shell(f'input swipe {phone_coordinate[2]}')
    # q
    elif predict_max == 16:
        device.shell(f'input tap {shot}')
    # r
    elif predict_max == 17:
        screenshot()
    # s
    elif predict_max == 18:
        appOpen()
    # t
    elif predict_max == 19:
        search()
    # u
    elif predict_max == 20:
        choose()
    # v
    elif predict_max == 21:
        device.shell('input keyevent --longpress KEYCODE_POWER')
    # w
    elif predict_max == 22:
        device.shell(f'input tap {center}')
        device.shell(f'input tap {center}')
    # x
    elif predict_max == 23:
        device.shell('input wm density 480')
    # y
    elif predict_max == 24:
        device.shell('input wm density 360')
    # z
    elif predict_max == 25:
        device.shell('input wm density reset')

def english_cmd(predict_max):
    global cmd, device
    cmd = f'{predict_max + 29}'

def number_cmd(predict_max):
    global cmd, device
    if predict_max < 10:
        cmd = f'{predict_max + 7}'
    else:
        print('temporarily unavailable')
        cmd = '-1'

while True:
    ret, img = video.read()
    ctime = time.time()
    cv2.putText(img, mode_kind[mode], (50, 50), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))
    cv2.putText(img, f'{chr(predict_max + 97)}', (50, 20), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

    # 投影畫面
    cv2.imshow('img', img)

    # 每隔1秒判斷一次
    if (ctime - ptime >= 2):
        ptime = ctime

        if ret:
            imgHeight = img.shape[0]
            imgWidth = img.shape[1]

            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            result = hands.process(imgRGB)
            if result.multi_hand_landmarks:
                for handLms in result.multi_hand_landmarks:

                    x5 = int(handLms.landmark[5].x * imgWidth)
                    y5 = int(handLms.landmark[5].y * imgHeight)

                    for i, lm in enumerate(handLms.landmark):
                        xPos = int(lm.x * imgWidth)
                        yPos = int(lm.y * imgHeight)

                        # 紀錄節點0座標並以節點0座標為基準
                        if i == 0:
                            x0 = xPos
                            y0 = yPos
                        xPos = xPos - x0
                        yPos = y0 - yPos

                        # 翻正
                        x_turn = False
                        y_turn = False
                        if i == 1:
                            if xPos < 0:
                                x_turn = True
                            if yPos < 0:
                                y_turn = True
                        if x_turn == True:
                            xPos = -xPos
                        if y_turn == True:
                            yPos = -yPos

                        # 紀錄0 ~ 5的距離
                        if i == 0:
                            x5 = x5 - x0
                            y5 = y5 - y0
                            length_standard = sqrt(x5 * x5 + y5 * y5)
                        xPos_ch = (xPos / length_standard)
                        yPos_ch = (yPos / length_standard)

                        x_train[i, 0] = xPos_ch
                        x_train[i, 1] = yPos_ch

                    # 導入模型進行運算
                    x_train = x_train.reshape((1, 42))
                    if mode == 0 or mode == 1:
                        predict = model_english.predict(x_train)
                    elif mode == 2:
                        predict = model_number.predict(x_train)
                    predict_max = np.argmax(predict, axis = -1)
                    predict_max = predict_max[0]

                    # 準確率
                    # print(predict[0][predict_max[0]])

                    # 去除雜訊
                    if predict[0][predict_max] < 0.7:
                        predict_max = 100

                    # 如果結果與之前相同則不運算
                    if pd_rem != predict_max:
                        if (predict_max == 100):
                            print("Recognition failed!")
                            restore_initial_value()
                            continue

                    # 印出辨識結果
                    print(chr(predict_max + 97))

                    # mode切換
                    if predict_max == 26:
                        print('切換模式')
                        pd_rem = 100
                        mode = (mode + 1) % len(mode_kind)

                    # 系統操作變換
                    if mode == 0:
                        tool_cmd(predict_max)
                    elif mode == 1:
                        english_cmd(predict_max)
                    elif mode == 2:
                        number_cmd(predict_max)

                    # 輸出指令
                    if cmd != '-1':
                        print("execute command!")
                        device.shell(f'input keyevent {cmd}')
                        cmd = '-1'

                    restore_initial_value()

    # 停止程式
    if cv2.waitKey(1) == ord('q'):
        break

"""##**模組切換**"""

import cv2
import time
import numpy as np
from math import sqrt
import mediapipe as mp
from keras.models import load_model
from cv2 import FONT_HERSHEY_SIMPLEX
from ppadb.client import Client as AdbClient

# 下載model
model_english = load_model('model_english.h5')
model_number = load_model('model_number.h5')

# 變數區域
cmd = 0
mode = 0
ctime = 0
ptime = 0
pd_rem = 100
predict_max = 100
whether_output = True
mode_kind = ['tool mode', 'English mode', 'Number mode']
mpHands = mp.solutions.hands
video = cv2.VideoCapture(0)
hands = mpHands.Hands()

x_train = np.empty([21, 2])

# 連線至裝置
def connect():
    client = AdbClient(host="127.0.0.1", port=5037) # Default is "127.0.0.1" and 5037

    devices = client.devices()

    if len(devices) == 0:
        print('No devices')
        quit()

    device = devices[0]

    print(f'Connected to {device}')

    return device, client

if __name__ == '__main__':
    device, client = connect()

def restore_initial_value():
    global x_train, pd_rem, predict_max

    # 將陣列歸零
    x_train = np.delete(x_train, slice(0, 42))
    x_train = np.zeros([21, 2])

    # 記錄前一個手勢
    pd_rem = predict_max

# 拍攝照片
shot = '550 2035'

# 中心點
center = '550 1200'

# 滑動座標設定
upswipe = '500 300 500 600'
downswipe = '500 600 500 300'
leftswipe = '100 800 1000 800'
rightswipe = '1000 800 100 800'

# 搜尋座標設定
search_bar_num = 0
search_bar = ['870 160', '440 200']
youtube_coordinate = ['500 650', '500 1700']
phone_coordinate = ['790 2050 790 1000', '550 2050', '300 2050 300 1000']

def search():
    global device
    query = input('你想搜尋(英文)：\n')
    search_query = f'{query}'
    device.shell(f'input tap {search_bar[search_bar_num]}')
    device.shell(f'input text "{search_query}"')
    time.sleep(1)
    device.shell('input keyevent 66')
    time.sleep(1)

def screenshot():
    global device
    screenshot = device.screencap()
    with open('result.png', 'wb') as f:
        f.write(screenshot)
        print('截圖已存檔！')

def appOpen():
    global search_bar_num, device
    command = {"youtube" : 'com.google.android.youtube/.HomeActivity',
           "line" : 'jp.naver.line.android/.activity.SplashActivity',
           "facebook" : 'com.facebook.katana/.LoginActivity',
           "google play" : 'com.android.vending/.AssetBrowserActivity',
           "google" : 'com.android.chrome/org.chromium.chrome.browser.ChromeTabbedActivity',
           "arknights" : 'tw.txwy.and.arknights/com.u8.sdk.U8UnityContext',
           "camera" : 'com.android.camera/.Camera'}
    print(command.keys())
    Input = input('which app do you want to open?\n')
    if Input == 'youtube':
        search_bar_num = 0
    elif Input == 'google':
        search_bar_num = 1
    device.shell(f'am start -n {command[Input]}')

def choose():
    choose = input('Which one?')
    device.shell(f'input tap {youtube_coordinate[int(choose) - 1]}')

def tool_cmd(predict_max):
    global cmd, device
    # a
    if predict_max == 0:
        cmd = '26'
    # b
    elif predict_max == 1:
        cmd = '3'
    # c
    elif predict_max == 2:
        cmd = '4'
    # d
    elif predict_max == 3:
        cmd = '221'
    # e
    elif predict_max == 4:
        cmd = '220'
    # f
    elif predict_max == 5:
        cmd = '24'
    # g
    elif predict_max == 6:
        cmd = '25'
    # h
    elif predict_max == 7:
        cmd = '19'
    # i
    elif predict_max == 8:
        cmd = '20'
    # j
    elif predict_max == 9:
        cmd = '21'
    # k
    elif predict_max == 10:
        cmd = '22'
    # l
    elif predict_max == 11:
        cmd = '66'
    # m
    elif predict_max == 12:
        cmd = '67'
    # n
    elif predict_max == 13:
        device.shell(f'input swipe {phone_coordinate[0]}')
    # o
    elif predict_max == 14:
        device.shell(f'input tap {phone_coordinate[1]}')
    # p
    elif predict_max == 15:
        device.shell(f'input swipe {phone_coordinate[2]}')
    # q
    elif predict_max == 16:
        device.shell(f'input tap {shot}')
    # r
    elif predict_max == 17:
        screenshot()
    # s
    elif predict_max == 18:
        appOpen()
    # t
    elif predict_max == 19:
        search()
    # u
    elif predict_max == 20:
        choose()
    # v
    elif predict_max == 21:
        device.shell('input keyevent --longpress KEYCODE_POWER')
    # w
    elif predict_max == 22:
        device.shell(f'input tap {center}')
        device.shell(f'input tap {center}')
    # x
    elif predict_max == 23:
        device.shell('input getevent')
    # y
    elif predict_max == 24:
        device.shell('input sendevent')
    # z
    elif predict_max == 25:
        device.shell('input wm density reset')

def english_cmd(predict_max):
    global cmd
    cmd = f'{predict_max + 29}'

def number_cmd(predict_max):
    global cmd
    cmd = f'{predict_max + 7}'

while True:
    ret, img = video.read()
    ctime = time.time()
    cv2.putText(img, mode_kind[mode], (50, 50), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))
    cv2.putText(img, f'{chr(predict_max + 97)}', (50, 20), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

    # 投影畫面
    cv2.imshow('img', img)

    # 每隔1秒判斷一次
    if (ctime - ptime >= 2):
        ptime = ctime

        if ret:
            imgHeight = img.shape[0]
            imgWidth = img.shape[1]

            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            result = hands.process(imgRGB)
            if result.multi_hand_landmarks:
                for handLms in result.multi_hand_landmarks:

                    x5 = int(handLms.landmark[5].x * imgWidth)
                    y5 = int(handLms.landmark[5].y * imgHeight)

                    for i, lm in enumerate(handLms.landmark):
                        xPos = int(lm.x * imgWidth)
                        yPos = int(lm.y * imgHeight)

                        # 紀錄節點0座標並以節點0座標為基準
                        if i == 0:
                            x0 = xPos
                            y0 = yPos
                        xPos = xPos - x0
                        yPos = y0 - yPos

                        # 翻正
                        x_turn = False
                        y_turn = False
                        if i == 1:
                            if xPos < 0:
                                x_turn = True
                            if yPos < 0:
                                y_turn = True
                        if x_turn == True:
                            xPos = -xPos
                        if y_turn == True:
                            yPos = -yPos

                        # 紀錄0 ~ 5的距離
                        if i == 0:
                            x5 = x5 - x0
                            y5 = y5 - y0
                            length_standard = sqrt(x5 * x5 + y5 * y5)
                        xPos_ch = (xPos / length_standard)
                        yPos_ch = (yPos / length_standard)

                        x_train[i, 0] = xPos_ch
                        x_train[i, 1] = yPos_ch

                    # 導入模型進行運算
                    x_train = x_train.reshape((1, 42))
                    if mode == 0 or mode == 1:
                        predict = model_english.predict(x_train)
                    elif mode == 2:
                        predict = model_number.predict(x_train)
                    predict_max = np.argmax(predict, axis = -1)
                    predict_max = predict_max[0]

                    # 準確率
                    # print(predict[0][predict_max[0]])

                    # 去除雜訊
                    if predict[0][predict_max] < 0.7:
                        predict_max = 100
                        print("Recognition failed!")
                        restore_initial_value()
                        continue

                    # 如果結果與之前相同則不運算
                    if pd_rem == predict_max:
                        restore_initial_value()
                        continue

                    # 印出辨識結果
                    print(chr(predict_max + 97))

                    # mode切換
                    if ((mode == 0 or 1) and predict_max == 26) or (mode == 2 and predict_max == 11):
                        print('切換模式')
                        pd_rem = 100
                        mode = (mode + 1) % len(mode_kind)

                    # 系統操作變換
                    if mode == 0:
                        tool_cmd(predict_max)
                    elif mode == 1:
                        english_cmd(predict_max)
                    elif mode == 2:
                        number_cmd(predict_max)

                    # 輸出指令
                    if cmd != '-1':
                        print("execute command!")
                        device.shell(f'input keyevent {cmd}')
                        cmd = '-1'

                    restore_initial_value()

    # 停止程式
    if cv2.waitKey(1) == ord('q'):
        break

"""##**細節修改**"""

import cv2
import time
import numpy as np
from math import sqrt
import mediapipe as mp
from keras.models import load_model
from cv2 import FONT_HERSHEY_SIMPLEX
from ppadb.client import Client as AdbClient

# 下載model
model_english = load_model('0220_2+9-english_lr=5-2-100-40.h5')
model_number = load_model('0220_2+9-number_lr=5-2-100-40.h5')

# 變數區域
cmd = 0
mode = 0
ctime = 0
ptime = 0
pd_rem = 100
predict_max = 100
output_word = '?'
whether_output = True
mode_kind = ['tool mode', 'English mode', 'Number mode']
mpHands = mp.solutions.hands
video = cv2.VideoCapture(0)
hands = mpHands.Hands()

x_train = np.empty([21, 2])

# 連線至裝置
def connect():
    client = AdbClient(host="127.0.0.1", port=5037) # Default is "127.0.0.1" and 5037

    devices = client.devices()

    if len(devices) == 0:
        print('No devices')
        quit()

    device = devices[0]

    print(f'Connected to {device}')

    return device, client

if __name__ == '__main__':
    device, client = connect()

def restore_initial_value():
    global x_train, pd_rem, predict_max

    # 將陣列歸零
    x_train = np.delete(x_train, slice(0, 42))
    x_train = np.zeros([21, 2])

    # 記錄前一個手勢
    pd_rem = predict_max

# 拍攝照片
shot = '550 2035'

# 中心點
center = '550 1200'

# 滑動座標設定
upswipe = '500 300 500 600'
downswipe = '500 600 500 300'
leftswipe = '100 800 1000 800'
rightswipe = '1000 800 100 800'

# 搜尋座標設定
search_bar_num = 0
search_bar = ['870 160', '440 200']
youtube_coordinate = ['500 650', '500 1700']
phone_coordinate = ['790 2050 790 1000', '550 2050', '300 2050 300 1000']

def search():
    global device
    query = input('你想搜尋(英文)：\n')
    search_query = f'{query}'
    device.shell(f'input tap {search_bar[search_bar_num]}')
    device.shell(f'input text "{search_query}"')
    time.sleep(1)
    device.shell('input keyevent 66')
    time.sleep(1)

def screenshot():
    global device
    screenshot = device.screencap()
    with open('result.png', 'wb') as f:
        f.write(screenshot)
        print('截圖已存檔！')

def appOpen():
    global search_bar_num, device
    command = {"youtube" : 'com.google.android.youtube/.HomeActivity',
           "line" : 'jp.naver.line.android/.activity.SplashActivity',
           "facebook" : 'com.facebook.katana/.LoginActivity',
           "google play" : 'com.android.vending/.AssetBrowserActivity',
           "google" : 'com.android.chrome/org.chromium.chrome.browser.ChromeTabbedActivity',
           "arknights" : 'tw.txwy.and.arknights/com.u8.sdk.U8UnityContext',
           "camera" : 'com.android.camera/.Camera'}
    print(command.keys())
    Input = input('which app do you want to open?\n')
    if Input == 'youtube':
        search_bar_num = 0
    elif Input == 'google':
        search_bar_num = 1
    device.shell(f'am start -n {command[Input]}')

def choose():
    choose = input('Which one?')
    device.shell(f'input tap {youtube_coordinate[int(choose) - 1]}')

def tool_cmd(predict_max):
    global cmd, device
    # a
    if predict_max == 0:
        cmd = '26'
    # b
    elif predict_max == 1:
        cmd = '3'
    # c
    elif predict_max == 2:
        cmd = '4'
    # d
    elif predict_max == 3:
        cmd = '221'
    # e
    elif predict_max == 4:
        cmd = '220'
    # f
    elif predict_max == 5:
        cmd = '24'
    # g
    elif predict_max == 6:
        cmd = '25'
    # h
    elif predict_max == 7:
        cmd = '19'
    # i
    elif predict_max == 8:
        cmd = '20'
    # j
    elif predict_max == 9:
        cmd = '21'
    # k
    elif predict_max == 10:
        cmd = '22'
    # l
    elif predict_max == 11:
        cmd = '66'
    # m
    elif predict_max == 12:
        cmd = '67'
    # n
    elif predict_max == 13:
        device.shell(f'input swipe {phone_coordinate[0]}')
    # o
    elif predict_max == 14:
        device.shell(f'input tap {phone_coordinate[1]}')
    # p
    elif predict_max == 15:
        device.shell(f'input swipe {phone_coordinate[2]}')
    # q
    elif predict_max == 16:
        device.shell(f'input tap {shot}')
    # r
    elif predict_max == 17:
        screenshot()
    # s
    elif predict_max == 18:
        appOpen()
    # t
    elif predict_max == 19:
        search()
    # u
    elif predict_max == 20:
        choose()
    # v
    elif predict_max == 21:
        device.shell('input keyevent --longpress KEYCODE_POWER')
    # w
    elif predict_max == 22:
        device.shell(f'input tap {center}')
        device.shell(f'input tap {center}')
    # x
    elif predict_max == 23:
        device.shell('input getevent')
    # y
    elif predict_max == 24:
        device.shell('input sendevent')
    # z
    elif predict_max == 25:
        device.shell('input wm density reset')

def english_cmd(predict_max):
    global cmd
    cmd = f'{predict_max + 29}'

def number_cmd(predict_max):
    global cmd
    cmd = f'{predict_max + 7}'

while True:
    ret, img = video.read()
    ctime = time.time()
    cv2.putText(img, mode_kind[mode], (50, 50), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))
    cv2.putText(img, f'{output_word}', (50, 20), FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0))

    # 投影畫面
    cv2.imshow('img', img)

    # 每隔1秒判斷一次
    if (ctime - ptime >= 2):
        ptime = ctime

        if ret:
            imgHeight = img.shape[0]
            imgWidth = img.shape[1]

            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            result = hands.process(imgRGB)
            if result.multi_hand_landmarks:
                for handLms in result.multi_hand_landmarks:

                    # 數值初始化
                    x5 = int(handLms.landmark[5].x * imgWidth)
                    y5 = int(handLms.landmark[5].y * imgHeight)
                    x_turn = False
                    y_turn = False

                    # 主程式
                    for i, lm in enumerate(handLms.landmark):
                        xPos = int(lm.x * imgWidth)
                        yPos = int(lm.y * imgHeight)

                        # 紀錄節點0座標並以節點0座標為基準
                        if i == 0:
                            x0 = xPos
                            y0 = yPos
                        xPos = xPos - x0
                        yPos = yPos - y0

                        # 將節點1定在第一象限
                        if i == 1:
                            if xPos < 0:
                                x_turn = True
                            if yPos < 0:
                                y_turn = True

                        # 翻正
                        if x_turn == True:
                            xPos = -xPos
                        if y_turn == True:
                            yPos = -yPos

                        # 紀錄0 ~ 5的距離
                        if i == 0:
                            x5 = x5 - x0
                            y5 = y5 - y0
                            length_standard = sqrt(x5 * x5 + y5 * y5)
                        xPos_ch = (xPos / length_standard)
                        yPos_ch = (yPos / length_standard)

                        # x_train資料存取
                        x_train[i, 0] = xPos_ch
                        x_train[i, 1] = yPos_ch

                    # 導入模型進行運算
                    x_train = x_train.reshape((1, 42))
                    if mode == 0 or mode == 1:
                        predict = model_english.predict(x_train)
                    elif mode == 2:
                        predict = model_number.predict(x_train)
                    predict_max = np.argmax(predict, axis = -1)
                    predict_max = predict_max[0]

                    # 準確率
                    # print(predict[0][predict_max[0]])

                    # 去除雜訊
                    if predict[0][predict_max] < 0.7:
                        predict_max = 100
                        print("Recognition failed!")
                        restore_initial_value()
                        continue

                    # 如果結果與之前相同則不運算
                    # if pd_rem == predict_max:
                    #     restore_initial_value()
                    #     continue

                    # mode切換
                    if ((mode == 0 or mode == 1) and predict_max == 26) or (mode == 2 and predict_max == 10):
                        print('切換模式')
                        pd_rem = 100
                        mode = (mode + 1) % len(mode_kind)

                    # 印出辨識結果
                    if (mode == 0 or mode == 1):
                        output_word = chr(predict_max + 97)
                    elif (mode == 2):
                        output_word = chr(predict_max + 48)
                    print(output_word, mode, predict_max)

                    # 系統操作變換
                    if mode == 0:
                        tool_cmd(predict_max)
                    elif mode == 1:
                        english_cmd(predict_max)
                    elif mode == 2:
                        number_cmd(predict_max)

                    # 輸出指令
                    if cmd != '-1':
                        print("execute command!")
                        device.shell(f'input keyevent {cmd}')
                        cmd = '-1'

                    restore_initial_value()

    # 停止程式
    if cv2.waitKey(1) == ord('q'):
        break